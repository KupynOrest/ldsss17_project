{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from extractor import get_features\n",
    "# from extractor\n",
    "os.listdir()\n",
    "\n",
    "data_dir = 'data'\n",
    "train_np_dir = 'train_np_subset'\n",
    "test_np_dir = 'test_np_subset'\n",
    "trained_weights_dir = 'trained_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 101\n"
     ]
    }
   ],
   "source": [
    "# Load existing clasess\n",
    "pkl_file = open('classes_dict.pickle', 'rb')\n",
    "\n",
    "classes_dict= pickle.load(pkl_file)\n",
    "\n",
    "pkl_file.close()\n",
    "\n",
    "print(classes_dict['PlayingGuitar'], len(classes_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "input_size = 512\n",
    "num_layers = 2\n",
    "batch_size = 300\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "num_classes = len(classes_dict)\n",
    "sequence_length = 50\n",
    "# label_str_to_int = {'ApplyEyeMakeup': 0, 'Archery': 1, 'ApplyLipstick': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN (\n",
       "  (lstm): LSTM(512, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear (128 -> 101)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda())\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "rnn = RNN(input_size=512, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes).cuda()\n",
    "rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU_rnn (\n",
       "  (lstm): GRU(512, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear (256 -> 101)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class GRU_rnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU_rnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda())\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "gru = GRU_rnn(input_size=512, hidden_size=256, num_layers=num_layers, num_classes=num_classes).cuda()\n",
    "gru\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available:  True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print (\"GPU is available: \", use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=7):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copute_dataset_size(path=''):\n",
    "    data_classes = [i for i in os.listdir(path) if not i.startswith('.')]\n",
    "    num_entries = 0\n",
    "\n",
    "    for folder in data_classes:\n",
    "        current_dir = path + '/' + folder + '/'\n",
    "        num_entries += len(os.listdir(current_dir))\n",
    "        \n",
    "    return num_entries\n",
    "\n",
    "train_size = copute_dataset_size(path=data_dir + '/' + train_np_dir)\n",
    "test_size = copute_dataset_size(path=data_dir + '/' + test_np_dir)\n",
    "\n",
    "def check_size(address, sequence_size=50):\n",
    "    x = np.load(address)\n",
    "    print (x.shape)\n",
    "    if x.shape[0] < sequence_size:\n",
    "        return np.concatenate((x, np.zeros((sequence_size - x.shape[0], x.shape[1]))), axis=0)\n",
    "    return x\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "def get_loader(path=''):\n",
    "    \"\"\"\n",
    "    Function reads .npy files from path.\n",
    "    Returns:\n",
    "        dataloader, data classes (list), size of input object [n_sequence, n_features], lenght_of_dataset\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    data_classes = [i for i in os.listdir(path) if not i.startswith('.')]\n",
    "\n",
    "    for folder in data_classes:\n",
    "        current_dir = path + '/' + folder + '/'\n",
    "        files = os.listdir(current_dir)\n",
    "        #test_f = np.load(current_dir + files[0])[:,:30,:]\n",
    "        \n",
    "#         print(test_f.shape)\n",
    "        temp = [torch.Tensor(np.load(current_dir +  f).reshape((sequence_length, input_size))) for f in files] \n",
    "                         # Transform to torch tensors\n",
    "        \n",
    "        targets += ([torch.LongTensor([classes_dict[folder]])] * len(temp))\n",
    "        inputs += temp\n",
    "\n",
    "    tensor_x = torch.stack(inputs)\n",
    "    tensor_y = torch.stack(targets)\n",
    "    my_dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)  # Create your datset\n",
    "    my_dataloader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size, shuffle=True)  # Create your dataloader\n",
    "\n",
    "    return (my_dataloader, data_classes)\n",
    "\n",
    "dset_loaders = {x: get_loader(data_dir + '/' + x)[0] for x in [train_np_dir, test_np_dir]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(data_dir + '/' + test_np_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_np_subset': 111, 'train_np_subset': 152}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {train_np_dir: train_size, test_np_dir: test_size}\n",
    "dset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, path, num_epochs=200, model_name='lstm'):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [train_np_dir, test_np_dir]:\n",
    "            if phase == train_np_dir:\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                # get the inputs\n",
    "                \n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "#                     print(inputs)\n",
    "                    inputs = Variable(inputs.view(-1, sequence_length, input_size).cuda())\n",
    "                    labels = Variable(labels.view(-1).cuda())                        \n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "#                 print (inputs.size())\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "#                 print (labels, outputs)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == train_np_dir:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "\n",
    "            print('running corrects: ', running_corrects)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == test_np_dir and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        # saving weights\n",
    "        torch.save(model, data_dir + '/' + trained_weights_dir + \"/\" + model_name + '_' + str(epoch) + \".pt\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "LR is set to 0.001\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  102\n",
      "test_np_subset Loss: 0.0038 Acc: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:147: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  102\n",
      "test_np_subset Loss: 0.0037 Acc: 0.9189\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  102\n",
      "test_np_subset Loss: 0.0038 Acc: 0.9189\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  102\n",
      "test_np_subset Loss: 0.0038 Acc: 0.9189\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  102\n",
      "test_np_subset Loss: 0.0038 Acc: 0.9189\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  100\n",
      "test_np_subset Loss: 0.0038 Acc: 0.9009\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0003 Acc: 1.0000\n",
      "running corrects:  100\n",
      "test_np_subset Loss: 0.0039 Acc: 0.9009\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  100\n",
      "test_np_subset Loss: 0.0039 Acc: 0.9009\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  100\n",
      "test_np_subset Loss: 0.0039 Acc: 0.9009\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  100\n",
      "test_np_subset Loss: 0.0039 Acc: 0.9009\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "LR is set to 1.0000000000000003e-05\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-06\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-07\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "LR is set to 1.0000000000000004e-08\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "LR is set to 1.0000000000000005e-09\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "LR is set to 1.0000000000000004e-10\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "LR is set to 1.0000000000000006e-11\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "LR is set to 1.0000000000000006e-12\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "LR is set to 1.0000000000000005e-13\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "LR is set to 1.0000000000000006e-14\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "LR is set to 1.0000000000000007e-15\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "LR is set to 1.0000000000000007e-16\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "LR is set to 1.0000000000000008e-17\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "running corrects:  152\n",
      "train_np_subset Loss: 0.0002 Acc: 1.0000\n",
      "running corrects:  99\n",
      "test_np_subset Loss: 0.0039 Acc: 0.8919\n",
      "\n",
      "Training complete in 0m 15s\n",
      "Best val Acc: 0.918919\n"
     ]
    }
   ],
   "source": [
    "model_lstm = train_model(rnn, criterion, optimizer, exp_lr_scheduler, '', num_epochs=num_epochs, model_name='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test set is not implemented yet\n",
    "\n",
    "# # Test the Model\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for images, labels in test_loader:\n",
    "#     images = Variable(images.view(-1, sequence_length, input_size))\n",
    "#     outputs = rnn(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum()\n",
    "\n",
    "# print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total)) \n",
    "\n",
    "# # Save the Model\n",
    "# # torch.save(rnn.state_dict(), 'rnn.pkl')\n",
    "# # torch.save(rnn, 'rnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feat = 100\n",
    "n_seq = 50 # fixed for now\n",
    "n_video = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4,5):\n",
    "    tmp_data = np.random.random((n_seq+1, n_feat))\n",
    "    np.save('data/features/Archery/v' + str(i) + '.npy', tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
