{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from extractor import get_features\n",
    "# from extractor\n",
    "os.listdir()\n",
    "\n",
    "data_dir = 'data'\n",
    "train_np_dir = 'train_np_subset'\n",
    "test_np_dir = 'test_np_subset'\n",
    "trained_weights_dir = 'trained_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "input_size = 512\n",
    "num_layers = 2\n",
    "batch_size = 30\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "num_classes = 3\n",
    "sequence_length = 50\n",
    "label_str_to_int = {'ApplyEyeMakeup': 0, 'Archery': 1, 'ApplyLipstick': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN (\n",
       "  (lstm): LSTM(512, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear (128 -> 3)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda())\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "rnn = RNN(input_size=512, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes).cuda()\n",
    "rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU_rnn (\n",
       "  (lstm): GRU(512, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear (256 -> 3)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class GRU_rnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU_rnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda())\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "gru = GRU_rnn(input_size=512, hidden_size=256, num_layers=num_layers, num_classes=num_classes).cuda()\n",
    "gru\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available:  True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print (\"GPU is available: \", use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=7):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_size(address, sequence_size=50):\n",
    "    x = np.load(address)\n",
    "    print (x.shape)\n",
    "    if x.shape[0] < sequence_size:\n",
    "        return np.concatenate((x, np.zeros((sequence_size - x.shape[0], x.shape[1]))), axis=0)\n",
    "    return x\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "def get_loader(path=''):\n",
    "    \"\"\"\n",
    "    Function reads .npy files from path.\n",
    "    Returns:\n",
    "        dataloader, data classes (list), size of input object [n_sequence, n_features], lenght_of_dataset\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    data_classes = [i for i in os.listdir(path) if not i.startswith('.')]\n",
    "    label_int = 0\n",
    "    for folder in data_classes:\n",
    "        current_dir = path + '/' + folder + '/'\n",
    "        files = os.listdir(current_dir)\n",
    "        #test_f = np.load(current_dir + files[0])[:,:30,:]\n",
    "        \n",
    "#         print(test_f.shape)\n",
    "        temp = [torch.Tensor(np.load(current_dir +  f).reshape((sequence_length, input_size))) for f in files] \n",
    "                         # Transform to torch tensors\n",
    "        \n",
    "        targets += ([torch.LongTensor([label_int])] * len(temp))\n",
    "        inputs += temp\n",
    "        \n",
    "        label_int += 1\n",
    "        \n",
    "    tensor_x = torch.stack(inputs)\n",
    "    tensor_y = torch.stack(targets)\n",
    "    my_dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)  # Create your datset\n",
    "    my_dataloader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size, shuffle=True)  # Create your dataloader\n",
    "    \n",
    "    \n",
    "    return (my_dataloader, data_classes)\n",
    "\n",
    "dset_loaders = {x: get_loader(data_dir + '/' + x)[0] for x in [train_np_dir, test_np_dir]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(data_dir + '/' + test_np_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset_sizes = {train_np_dir: 100, test_np_dir: 100}  # <-- Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, path, num_epochs=200, model_name='lstm'):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [train_np_dir, test_np_dir]:\n",
    "            if phase == train_np_dir:\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                # get the inputs\n",
    "                \n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "#                     print(inputs)\n",
    "                    inputs = Variable(inputs.view(-1, sequence_length, input_size).cuda())\n",
    "                    labels = Variable(labels.view(-1).cuda())                        \n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "\n",
    "                    \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "#                 print (inputs.size())\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == train_np_dir:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == test_np_dir and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        # saving weights\n",
    "        torch.save(model, data_dir + '/' + trained_weights_dir + \"/\" + model_name + '_' + str(epoch) + \".pt\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "LR is set to 0.001\n",
      "train_np_subset Loss: 0.0574 Acc: 0.8600\n",
      "test_np_subset Loss: 0.0332 Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:147: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0278 Acc: 1.4800\n",
      "test_np_subset Loss: 0.0182 Acc: 1.0000\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0060 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0129 Acc: 1.0300\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0011 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0178 Acc: 1.0100\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0003 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0212 Acc: 1.0100\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0002 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0258 Acc: 1.0100\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0259 Acc: 1.0100\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0271 Acc: 1.0100\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0273 Acc: 1.0100\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0263 Acc: 1.0100\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0274 Acc: 1.0100\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0306 Acc: 1.0100\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "LR is set to 1.0000000000000003e-05\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0244 Acc: 1.0100\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0286 Acc: 1.0100\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0244 Acc: 1.0100\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0286 Acc: 1.0100\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-06\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-07\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "LR is set to 1.0000000000000004e-08\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0287 Acc: 1.0100\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "LR is set to 1.0000000000000005e-09\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0287 Acc: 1.0100\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "LR is set to 1.0000000000000004e-10\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "LR is set to 1.0000000000000006e-11\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0286 Acc: 1.0100\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "LR is set to 1.0000000000000006e-12\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0287 Acc: 1.0100\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0277 Acc: 1.0100\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "LR is set to 1.0000000000000005e-13\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 75/199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "LR is set to 1.0000000000000006e-14\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0264 Acc: 1.0100\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "LR is set to 1.0000000000000007e-15\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0286 Acc: 1.0100\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0277 Acc: 1.0100\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "LR is set to 1.0000000000000007e-16\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0287 Acc: 1.0100\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "LR is set to 1.0000000000000008e-17\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0296 Acc: 1.0100\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "LR is set to 1.0000000000000008e-18\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0285 Acc: 1.0100\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "LR is set to 1.0000000000000008e-19\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0285 Acc: 1.0100\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "LR is set to 1.000000000000001e-20\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0297 Acc: 1.0100\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0296 Acc: 1.0100\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "LR is set to 1.000000000000001e-21\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0296 Acc: 1.0100\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0256 Acc: 1.0100\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "LR is set to 1.0000000000000011e-22\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0277 Acc: 1.0100\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "LR is set to 1.0000000000000011e-23\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0297 Acc: 1.0100\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0287 Acc: 1.0100\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "LR is set to 1.0000000000000012e-24\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0286 Acc: 1.0100\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "LR is set to 1.0000000000000013e-25\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0287 Acc: 1.0100\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0296 Acc: 1.0100\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "LR is set to 1.0000000000000013e-26\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "LR is set to 1.0000000000000015e-27\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0264 Acc: 1.0100\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0296 Acc: 1.0100\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "LR is set to 1.0000000000000014e-28\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0254 Acc: 1.0100\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "LR is set to 1.0000000000000015e-29\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0265 Acc: 1.0100\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "LR is set to 1.0000000000000015e-30\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0275 Acc: 1.0100\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0276 Acc: 1.0100\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "LR is set to 1.0000000000000016e-31\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0255 Acc: 1.0100\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0286 Acc: 1.0100\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0245 Acc: 1.0100\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train_np_subset Loss: 0.0001 Acc: 1.5200\n",
      "test_np_subset Loss: 0.0266 Acc: 1.0100\n",
      "\n",
      "Training complete in 0m 47s\n",
      "Best val Acc: 1.030000\n"
     ]
    }
   ],
   "source": [
    "model_lstm = train_model(rnn, criterion, optimizer, exp_lr_scheduler, '', num_epochs=200, model_name='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     for i, (labels, images) in enumerate(get_features(in_dir='data/data_subset/', batch_size=10)):\n",
    "#         print (images.size())\n",
    "#         labels = torch.LongTensor([label_str_to_int[i] for i in labels]).cuda()\n",
    "        \n",
    "# #         print (type(images), type(labels))\n",
    "# #         print (images)\n",
    "# #         print(labels)\n",
    "\n",
    "#         images = Variable(images.view(-1, sequence_length, input_size).cuda())\n",
    "#         labels = Variable(labels.view(-1).cuda())\n",
    "\n",
    "#         # Forward + Backward + Optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = rnn(images)\n",
    "\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if (i+1) % 1 == 0:\n",
    "#             print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, 100000//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test set is not implemented yet\n",
    "\n",
    "# # Test the Model\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for images, labels in test_loader:\n",
    "#     images = Variable(images.view(-1, sequence_length, input_size))\n",
    "#     outputs = rnn(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum()\n",
    "\n",
    "# print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total)) \n",
    "\n",
    "# # Save the Model\n",
    "# # torch.save(rnn.state_dict(), 'rnn.pkl')\n",
    "# # torch.save(rnn, 'rnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feat = 100\n",
    "n_seq = 50 # fixed for now\n",
    "n_video = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4,5):\n",
    "    tmp_data = np.random.random((n_seq+1, n_feat))\n",
    "    np.save('data/features/Archery/v' + str(i) + '.npy', tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
