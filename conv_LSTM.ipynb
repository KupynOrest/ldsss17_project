{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from extractor import get_features\n",
    "# from extractor\n",
    "os.listdir()\n",
    "\n",
    "data_dir = 'data'\n",
    "train_np_dir = 'train_np_med'\n",
    "test_np_dir = 'test_np_med'\n",
    "trained_weights_dir = 'trained_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 101\n"
     ]
    }
   ],
   "source": [
    "# Load existing clasess\n",
    "pkl_file = open('classes_dict.pickle', 'rb')\n",
    "\n",
    "classes_dict= pickle.load(pkl_file)\n",
    "\n",
    "pkl_file.close()\n",
    "\n",
    "print(classes_dict['PlayingGuitar'], len(classes_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "input_size = 512\n",
    "num_layers = 2\n",
    "dropout = 0.8\n",
    "batch_size = 1000\n",
    "num_epochs = 200\n",
    "learning_rate = 0.1\n",
    "num_classes = len(classes_dict)\n",
    "sequence_length = 50\n",
    "# label_str_to_int = {'ApplyEyeMakeup': 0, 'Archery': 1, 'ApplyLipstick': 2}\n",
    "\n",
    "# Best results:\n",
    "# h:128 num: 3 drop: 0.5 lr: 0.1   result: 0.580756\n",
    "\n",
    "# Very best result till now:\n",
    "# h: 256 num: 2 drop: 0.8 lr: 0.1   result: 0.630188"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN (\n",
       "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.8)\n",
       "  (fc): Linear (256 -> 101)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda())\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "rnn = RNN(input_size=512, hidden_size=hidden_size,\n",
    "          num_layers=num_layers, num_classes=num_classes, dropout=dropout).cuda()\n",
    "rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available:  True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print (\"GPU is available: \", use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.01, lr_decay_epoch=50):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.5**(epoch // lr_decay_epoch))\n",
    "#     lr = init_lr #* 1 / (1 + )\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copute_dataset_size(path=''):\n",
    "    data_classes = [i for i in os.listdir(path) if not i.startswith('.')]\n",
    "    num_entries = 0\n",
    "\n",
    "    for folder in data_classes:\n",
    "        current_dir = path + '/' + folder + '/'\n",
    "        num_entries += len(os.listdir(current_dir))\n",
    "        \n",
    "    return num_entries\n",
    "\n",
    "train_size = copute_dataset_size(path=data_dir + '/' + train_np_dir)\n",
    "test_size = copute_dataset_size(path=data_dir + '/' + test_np_dir)\n",
    "\n",
    "def check_size(address, sequence_size=50):\n",
    "    x = np.load(address)\n",
    "    print (x.shape)\n",
    "    if x.shape[0] < sequence_size:\n",
    "        return np.concatenate((x, np.zeros((sequence_size - x.shape[0], x.shape[1]))), axis=0)\n",
    "    return x\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "def get_loader(path='', batch_size=batch_size):\n",
    "    \"\"\"\n",
    "    Function reads .npy files from path.\n",
    "    Returns:\n",
    "        dataloader, data classes (list), size of input object [n_sequence, n_features], lenght_of_dataset\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    data_classes = [i for i in os.listdir(path) if not i.startswith('.')]\n",
    "\n",
    "    for folder in data_classes:\n",
    "        current_dir = path + '/' + folder + '/'\n",
    "        files = os.listdir(current_dir)\n",
    "        #test_f = np.load(current_dir + files[0])[:,:30,:]\n",
    "        \n",
    "#         print(test_f.shape)\n",
    "        temp = [torch.Tensor(np.load(current_dir +  f).reshape((sequence_length, input_size))) for f in files] \n",
    "                         # Transform to torch tensors\n",
    "        \n",
    "        targets += ([torch.LongTensor([classes_dict[folder]])] * len(temp))\n",
    "        inputs += temp\n",
    "\n",
    "    tensor_x = torch.stack(inputs)\n",
    "    tensor_y = torch.stack(targets)\n",
    "    my_dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)  # Create your datset\n",
    "    my_dataloader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size, shuffle=True)  # Create your dataloader\n",
    "\n",
    "    return (my_dataloader, data_classes)\n",
    "\n",
    "dset_loaders = {x: get_loader(data_dir + '/' + x)[0] for x in [train_np_dir, test_np_dir]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(data_dir + '/' + test_np_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_np_med': 3783, 'train_np_med': 9522}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {train_np_dir: train_size, test_np_dir: test_size}\n",
    "dset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, path, num_epochs=200, model_name='lstm'):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [train_np_dir, test_np_dir]:\n",
    "            if phase == train_np_dir:\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            counter = 0\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                # get the inputs\n",
    "\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "#                     print(inputs)\n",
    "                    inputs = Variable(inputs.view(-1, sequence_length, input_size).cuda())\n",
    "                    labels = Variable(labels.view(-1).cuda())                        \n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "#                 print (inputs.size())\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "#                 print (labels, outputs)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == train_np_dir:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#             print(preds, labels.data, '\\n========')\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "\n",
    "            print('running corrects: ', running_corrects)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == test_np_dir and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        # saving weights\n",
    "        torch.save(model, data_dir + '/' + trained_weights_dir + \"/\" + model_name + '_' + str(epoch) + \".pt\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "LR is set to 0.01\n",
      "running corrects:  181\n",
      "train_np_med Loss: 0.0048 Acc: 0.0190\n",
      "running corrects:  149\n",
      "test_np_med Loss: 0.0047 Acc: 0.0394\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip/.virtualenvs/cv3/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running corrects:  531\n",
      "train_np_med Loss: 0.0043 Acc: 0.0558\n",
      "running corrects:  316\n",
      "test_np_med Loss: 0.0039 Acc: 0.0835\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "running corrects:  1272\n",
      "train_np_med Loss: 0.0035 Acc: 0.1336\n",
      "running corrects:  600\n",
      "test_np_med Loss: 0.0033 Acc: 0.1586\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "running corrects:  1915\n",
      "train_np_med Loss: 0.0030 Acc: 0.2011\n",
      "running corrects:  869\n",
      "test_np_med Loss: 0.0030 Acc: 0.2297\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "running corrects:  2562\n",
      "train_np_med Loss: 0.0027 Acc: 0.2691\n",
      "running corrects:  957\n",
      "test_np_med Loss: 0.0028 Acc: 0.2530\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "running corrects:  2989\n",
      "train_np_med Loss: 0.0025 Acc: 0.3139\n",
      "running corrects:  1257\n",
      "test_np_med Loss: 0.0026 Acc: 0.3323\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "running corrects:  3564\n",
      "train_np_med Loss: 0.0022 Acc: 0.3743\n",
      "running corrects:  1334\n",
      "test_np_med Loss: 0.0024 Acc: 0.3526\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "running corrects:  3879\n",
      "train_np_med Loss: 0.0021 Acc: 0.4074\n",
      "running corrects:  1277\n",
      "test_np_med Loss: 0.0024 Acc: 0.3376\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "running corrects:  3907\n",
      "train_np_med Loss: 0.0021 Acc: 0.4103\n",
      "running corrects:  1292\n",
      "test_np_med Loss: 0.0025 Acc: 0.3415\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "running corrects:  4324\n",
      "train_np_med Loss: 0.0019 Acc: 0.4541\n",
      "running corrects:  1443\n",
      "test_np_med Loss: 0.0023 Acc: 0.3814\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "running corrects:  4855\n",
      "train_np_med Loss: 0.0017 Acc: 0.5099\n",
      "running corrects:  1587\n",
      "test_np_med Loss: 0.0022 Acc: 0.4195\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "running corrects:  5151\n",
      "train_np_med Loss: 0.0016 Acc: 0.5410\n",
      "running corrects:  1679\n",
      "test_np_med Loss: 0.0021 Acc: 0.4438\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "running corrects:  5480\n",
      "train_np_med Loss: 0.0014 Acc: 0.5755\n",
      "running corrects:  1663\n",
      "test_np_med Loss: 0.0021 Acc: 0.4396\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "running corrects:  5735\n",
      "train_np_med Loss: 0.0013 Acc: 0.6023\n",
      "running corrects:  1770\n",
      "test_np_med Loss: 0.0020 Acc: 0.4679\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "running corrects:  5988\n",
      "train_np_med Loss: 0.0012 Acc: 0.6289\n",
      "running corrects:  1814\n",
      "test_np_med Loss: 0.0020 Acc: 0.4795\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "running corrects:  6315\n",
      "train_np_med Loss: 0.0011 Acc: 0.6632\n",
      "running corrects:  1813\n",
      "test_np_med Loss: 0.0020 Acc: 0.4792\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "running corrects:  6346\n",
      "train_np_med Loss: 0.0011 Acc: 0.6665\n",
      "running corrects:  1838\n",
      "test_np_med Loss: 0.0020 Acc: 0.4859\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "running corrects:  6554\n",
      "train_np_med Loss: 0.0010 Acc: 0.6883\n",
      "running corrects:  1843\n",
      "test_np_med Loss: 0.0020 Acc: 0.4872\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "running corrects:  6675\n",
      "train_np_med Loss: 0.0010 Acc: 0.7010\n",
      "running corrects:  1853\n",
      "test_np_med Loss: 0.0020 Acc: 0.4898\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "running corrects:  6745\n",
      "train_np_med Loss: 0.0009 Acc: 0.7084\n",
      "running corrects:  1819\n",
      "test_np_med Loss: 0.0020 Acc: 0.4808\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "running corrects:  6991\n",
      "train_np_med Loss: 0.0009 Acc: 0.7342\n",
      "running corrects:  1973\n",
      "test_np_med Loss: 0.0019 Acc: 0.5215\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "running corrects:  7231\n",
      "train_np_med Loss: 0.0008 Acc: 0.7594\n",
      "running corrects:  1971\n",
      "test_np_med Loss: 0.0019 Acc: 0.5210\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "running corrects:  7418\n",
      "train_np_med Loss: 0.0007 Acc: 0.7790\n",
      "running corrects:  2005\n",
      "test_np_med Loss: 0.0019 Acc: 0.5300\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "running corrects:  7528\n",
      "train_np_med Loss: 0.0007 Acc: 0.7906\n",
      "running corrects:  2046\n",
      "test_np_med Loss: 0.0018 Acc: 0.5408\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "running corrects:  7656\n",
      "train_np_med Loss: 0.0006 Acc: 0.8040\n",
      "running corrects:  2029\n",
      "test_np_med Loss: 0.0020 Acc: 0.5363\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "running corrects:  7684\n",
      "train_np_med Loss: 0.0006 Acc: 0.8070\n",
      "running corrects:  2037\n",
      "test_np_med Loss: 0.0019 Acc: 0.5385\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "running corrects:  7757\n",
      "train_np_med Loss: 0.0006 Acc: 0.8146\n",
      "running corrects:  2037\n",
      "test_np_med Loss: 0.0019 Acc: 0.5385\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "running corrects:  7794\n",
      "train_np_med Loss: 0.0006 Acc: 0.8185\n",
      "running corrects:  2077\n",
      "test_np_med Loss: 0.0019 Acc: 0.5490\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "running corrects:  7960\n",
      "train_np_med Loss: 0.0005 Acc: 0.8360\n",
      "running corrects:  2124\n",
      "test_np_med Loss: 0.0019 Acc: 0.5615\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "running corrects:  8062\n",
      "train_np_med Loss: 0.0005 Acc: 0.8467\n",
      "running corrects:  2073\n",
      "test_np_med Loss: 0.0019 Acc: 0.5480\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "running corrects:  8153\n",
      "train_np_med Loss: 0.0005 Acc: 0.8562\n",
      "running corrects:  2090\n",
      "test_np_med Loss: 0.0020 Acc: 0.5525\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "running corrects:  8147\n",
      "train_np_med Loss: 0.0005 Acc: 0.8556\n",
      "running corrects:  2072\n",
      "test_np_med Loss: 0.0019 Acc: 0.5477\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "running corrects:  8142\n",
      "train_np_med Loss: 0.0005 Acc: 0.8551\n",
      "running corrects:  2102\n",
      "test_np_med Loss: 0.0018 Acc: 0.5556\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "running corrects:  8222\n",
      "train_np_med Loss: 0.0004 Acc: 0.8635\n",
      "running corrects:  2121\n",
      "test_np_med Loss: 0.0019 Acc: 0.5607\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "running corrects:  8347\n",
      "train_np_med Loss: 0.0004 Acc: 0.8766\n",
      "running corrects:  2154\n",
      "test_np_med Loss: 0.0019 Acc: 0.5694\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "running corrects:  8330\n",
      "train_np_med Loss: 0.0004 Acc: 0.8748\n",
      "running corrects:  2123\n",
      "test_np_med Loss: 0.0019 Acc: 0.5612\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "running corrects:  8501\n",
      "train_np_med Loss: 0.0003 Acc: 0.8928\n",
      "running corrects:  2159\n",
      "test_np_med Loss: 0.0019 Acc: 0.5707\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "running corrects:  8575\n",
      "train_np_med Loss: 0.0003 Acc: 0.9005\n",
      "running corrects:  2198\n",
      "test_np_med Loss: 0.0019 Acc: 0.5810\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "running corrects:  8594\n",
      "train_np_med Loss: 0.0003 Acc: 0.9025\n",
      "running corrects:  2178\n",
      "test_np_med Loss: 0.0019 Acc: 0.5757\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "running corrects:  8697\n",
      "train_np_med Loss: 0.0003 Acc: 0.9134\n",
      "running corrects:  2154\n",
      "test_np_med Loss: 0.0019 Acc: 0.5694\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "running corrects:  8650\n",
      "train_np_med Loss: 0.0003 Acc: 0.9084\n",
      "running corrects:  2145\n",
      "test_np_med Loss: 0.0020 Acc: 0.5670\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "running corrects:  8613\n",
      "train_np_med Loss: 0.0003 Acc: 0.9045\n",
      "running corrects:  2085\n",
      "test_np_med Loss: 0.0021 Acc: 0.5511\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "running corrects:  8595\n",
      "train_np_med Loss: 0.0003 Acc: 0.9026\n",
      "running corrects:  2151\n",
      "test_np_med Loss: 0.0019 Acc: 0.5686\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "running corrects:  8637\n",
      "train_np_med Loss: 0.0003 Acc: 0.9071\n",
      "running corrects:  2136\n",
      "test_np_med Loss: 0.0020 Acc: 0.5646\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "running corrects:  8740\n",
      "train_np_med Loss: 0.0003 Acc: 0.9179\n",
      "running corrects:  2145\n",
      "test_np_med Loss: 0.0021 Acc: 0.5670\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "running corrects:  8844\n",
      "train_np_med Loss: 0.0002 Acc: 0.9288\n",
      "running corrects:  2180\n",
      "test_np_med Loss: 0.0020 Acc: 0.5763\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "running corrects:  8845\n",
      "train_np_med Loss: 0.0002 Acc: 0.9289\n",
      "running corrects:  2172\n",
      "test_np_med Loss: 0.0021 Acc: 0.5741\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "running corrects:  8855\n",
      "train_np_med Loss: 0.0002 Acc: 0.9300\n",
      "running corrects:  2177\n",
      "test_np_med Loss: 0.0021 Acc: 0.5755\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "running corrects:  8827\n",
      "train_np_med Loss: 0.0002 Acc: 0.9270\n",
      "running corrects:  2209\n",
      "test_np_med Loss: 0.0020 Acc: 0.5839\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "running corrects:  8816\n",
      "train_np_med Loss: 0.0002 Acc: 0.9259\n",
      "running corrects:  2182\n",
      "test_np_med Loss: 0.0021 Acc: 0.5768\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "LR is set to 0.005\n",
      "running corrects:  8959\n",
      "train_np_med Loss: 0.0002 Acc: 0.9409\n",
      "running corrects:  2216\n",
      "test_np_med Loss: 0.0021 Acc: 0.5858\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "running corrects:  9030\n",
      "train_np_med Loss: 0.0002 Acc: 0.9483\n",
      "running corrects:  2238\n",
      "test_np_med Loss: 0.0020 Acc: 0.5916\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "running corrects:  9103\n",
      "train_np_med Loss: 0.0001 Acc: 0.9560\n",
      "running corrects:  2239\n",
      "test_np_med Loss: 0.0021 Acc: 0.5919\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "running corrects:  9166\n",
      "train_np_med Loss: 0.0001 Acc: 0.9626\n",
      "running corrects:  2205\n",
      "test_np_med Loss: 0.0021 Acc: 0.5829\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "running corrects:  9156\n",
      "train_np_med Loss: 0.0001 Acc: 0.9616\n",
      "running corrects:  2222\n",
      "test_np_med Loss: 0.0021 Acc: 0.5874\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "running corrects:  9169\n",
      "train_np_med Loss: 0.0001 Acc: 0.9629\n",
      "running corrects:  2250\n",
      "test_np_med Loss: 0.0021 Acc: 0.5948\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "running corrects:  9219\n",
      "train_np_med Loss: 0.0001 Acc: 0.9682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running corrects:  2233\n",
      "test_np_med Loss: 0.0021 Acc: 0.5903\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "running corrects:  9251\n",
      "train_np_med Loss: 0.0001 Acc: 0.9715\n",
      "running corrects:  2261\n",
      "test_np_med Loss: 0.0021 Acc: 0.5977\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "running corrects:  9248\n",
      "train_np_med Loss: 0.0001 Acc: 0.9712\n",
      "running corrects:  2250\n",
      "test_np_med Loss: 0.0021 Acc: 0.5948\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "running corrects:  9255\n",
      "train_np_med Loss: 0.0001 Acc: 0.9720\n",
      "running corrects:  2280\n",
      "test_np_med Loss: 0.0021 Acc: 0.6027\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "running corrects:  9237\n",
      "train_np_med Loss: 0.0001 Acc: 0.9701\n",
      "running corrects:  2270\n",
      "test_np_med Loss: 0.0021 Acc: 0.6001\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "running corrects:  9303\n",
      "train_np_med Loss: 0.0001 Acc: 0.9770\n",
      "running corrects:  2264\n",
      "test_np_med Loss: 0.0021 Acc: 0.5985\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "running corrects:  9306\n",
      "train_np_med Loss: 0.0001 Acc: 0.9773\n",
      "running corrects:  2293\n",
      "test_np_med Loss: 0.0021 Acc: 0.6061\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "running corrects:  9293\n",
      "train_np_med Loss: 0.0001 Acc: 0.9760\n",
      "running corrects:  2266\n",
      "test_np_med Loss: 0.0022 Acc: 0.5990\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "running corrects:  9296\n",
      "train_np_med Loss: 0.0001 Acc: 0.9763\n",
      "running corrects:  2255\n",
      "test_np_med Loss: 0.0022 Acc: 0.5961\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "running corrects:  9271\n",
      "train_np_med Loss: 0.0001 Acc: 0.9736\n",
      "running corrects:  2282\n",
      "test_np_med Loss: 0.0021 Acc: 0.6032\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "running corrects:  9301\n",
      "train_np_med Loss: 0.0001 Acc: 0.9768\n",
      "running corrects:  2297\n",
      "test_np_med Loss: 0.0021 Acc: 0.6072\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "running corrects:  9307\n",
      "train_np_med Loss: 0.0001 Acc: 0.9774\n",
      "running corrects:  2307\n",
      "test_np_med Loss: 0.0021 Acc: 0.6098\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "running corrects:  9318\n",
      "train_np_med Loss: 0.0001 Acc: 0.9786\n",
      "running corrects:  2294\n",
      "test_np_med Loss: 0.0022 Acc: 0.6064\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "running corrects:  9298\n",
      "train_np_med Loss: 0.0001 Acc: 0.9765\n",
      "running corrects:  2277\n",
      "test_np_med Loss: 0.0022 Acc: 0.6019\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "running corrects:  9289\n",
      "train_np_med Loss: 0.0001 Acc: 0.9755\n",
      "running corrects:  2269\n",
      "test_np_med Loss: 0.0022 Acc: 0.5998\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "running corrects:  9304\n",
      "train_np_med Loss: 0.0001 Acc: 0.9771\n",
      "running corrects:  2268\n",
      "test_np_med Loss: 0.0022 Acc: 0.5995\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "running corrects:  9324\n",
      "train_np_med Loss: 0.0001 Acc: 0.9792\n",
      "running corrects:  2262\n",
      "test_np_med Loss: 0.0022 Acc: 0.5979\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "running corrects:  9331\n",
      "train_np_med Loss: 0.0001 Acc: 0.9799\n",
      "running corrects:  2276\n",
      "test_np_med Loss: 0.0022 Acc: 0.6016\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "running corrects:  9316\n",
      "train_np_med Loss: 0.0001 Acc: 0.9784\n",
      "running corrects:  2233\n",
      "test_np_med Loss: 0.0023 Acc: 0.5903\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "running corrects:  9354\n",
      "train_np_med Loss: 0.0001 Acc: 0.9824\n",
      "running corrects:  2307\n",
      "test_np_med Loss: 0.0022 Acc: 0.6098\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "running corrects:  9357\n",
      "train_np_med Loss: 0.0001 Acc: 0.9827\n",
      "running corrects:  2308\n",
      "test_np_med Loss: 0.0022 Acc: 0.6101\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "running corrects:  9365\n",
      "train_np_med Loss: 0.0001 Acc: 0.9835\n",
      "running corrects:  2277\n",
      "test_np_med Loss: 0.0023 Acc: 0.6019\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "running corrects:  9364\n",
      "train_np_med Loss: 0.0001 Acc: 0.9834\n",
      "running corrects:  2267\n",
      "test_np_med Loss: 0.0022 Acc: 0.5993\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "running corrects:  9345\n",
      "train_np_med Loss: 0.0001 Acc: 0.9814\n",
      "running corrects:  2295\n",
      "test_np_med Loss: 0.0023 Acc: 0.6067\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "running corrects:  9332\n",
      "train_np_med Loss: 0.0001 Acc: 0.9800\n",
      "running corrects:  2313\n",
      "test_np_med Loss: 0.0022 Acc: 0.6114\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "running corrects:  9360\n",
      "train_np_med Loss: 0.0001 Acc: 0.9830\n",
      "running corrects:  2317\n",
      "test_np_med Loss: 0.0022 Acc: 0.6125\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "running corrects:  9358\n",
      "train_np_med Loss: 0.0001 Acc: 0.9828\n",
      "running corrects:  2288\n",
      "test_np_med Loss: 0.0022 Acc: 0.6048\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "running corrects:  9371\n",
      "train_np_med Loss: 0.0001 Acc: 0.9841\n",
      "running corrects:  2284\n",
      "test_np_med Loss: 0.0022 Acc: 0.6038\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "running corrects:  9377\n",
      "train_np_med Loss: 0.0001 Acc: 0.9848\n",
      "running corrects:  2287\n",
      "test_np_med Loss: 0.0022 Acc: 0.6045\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "running corrects:  9388\n",
      "train_np_med Loss: 0.0001 Acc: 0.9859\n",
      "running corrects:  2290\n",
      "test_np_med Loss: 0.0022 Acc: 0.6053\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "running corrects:  9389\n",
      "train_np_med Loss: 0.0000 Acc: 0.9860\n",
      "running corrects:  2299\n",
      "test_np_med Loss: 0.0022 Acc: 0.6077\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "running corrects:  9392\n",
      "train_np_med Loss: 0.0001 Acc: 0.9863\n",
      "running corrects:  2310\n",
      "test_np_med Loss: 0.0022 Acc: 0.6106\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "running corrects:  9394\n",
      "train_np_med Loss: 0.0000 Acc: 0.9866\n",
      "running corrects:  2296\n",
      "test_np_med Loss: 0.0023 Acc: 0.6069\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "running corrects:  9388\n",
      "train_np_med Loss: 0.0001 Acc: 0.9859\n",
      "running corrects:  2306\n",
      "test_np_med Loss: 0.0023 Acc: 0.6096\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "running corrects:  9401\n",
      "train_np_med Loss: 0.0000 Acc: 0.9873\n",
      "running corrects:  2318\n",
      "test_np_med Loss: 0.0023 Acc: 0.6127\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "running corrects:  9398\n",
      "train_np_med Loss: 0.0000 Acc: 0.9870\n",
      "running corrects:  2275\n",
      "test_np_med Loss: 0.0023 Acc: 0.6014\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "running corrects:  9391\n",
      "train_np_med Loss: 0.0001 Acc: 0.9862\n",
      "running corrects:  2303\n",
      "test_np_med Loss: 0.0022 Acc: 0.6088\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "running corrects:  9406\n",
      "train_np_med Loss: 0.0000 Acc: 0.9878\n",
      "running corrects:  2304\n",
      "test_np_med Loss: 0.0023 Acc: 0.6090\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "running corrects:  9383\n",
      "train_np_med Loss: 0.0001 Acc: 0.9854\n",
      "running corrects:  2299\n",
      "test_np_med Loss: 0.0023 Acc: 0.6077\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "running corrects:  9374\n",
      "train_np_med Loss: 0.0001 Acc: 0.9845\n",
      "running corrects:  2288\n",
      "test_np_med Loss: 0.0023 Acc: 0.6048\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "running corrects:  9377\n",
      "train_np_med Loss: 0.0001 Acc: 0.9848\n",
      "running corrects:  2290\n",
      "test_np_med Loss: 0.0023 Acc: 0.6053\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "running corrects:  9392\n",
      "train_np_med Loss: 0.0000 Acc: 0.9863\n",
      "running corrects:  2300\n",
      "test_np_med Loss: 0.0023 Acc: 0.6080\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "running corrects:  9414\n",
      "train_np_med Loss: 0.0000 Acc: 0.9887\n",
      "running corrects:  2319\n",
      "test_np_med Loss: 0.0022 Acc: 0.6130\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "running corrects:  9419\n",
      "train_np_med Loss: 0.0000 Acc: 0.9892\n",
      "running corrects:  2304\n",
      "test_np_med Loss: 0.0022 Acc: 0.6090\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "LR is set to 0.0025\n",
      "running corrects:  9427\n",
      "train_np_med Loss: 0.0000 Acc: 0.9900\n",
      "running corrects:  2342\n",
      "test_np_med Loss: 0.0022 Acc: 0.6191\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "running corrects:  9457\n",
      "train_np_med Loss: 0.0000 Acc: 0.9932\n",
      "running corrects:  2335\n",
      "test_np_med Loss: 0.0022 Acc: 0.6172\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "running corrects:  9452\n",
      "train_np_med Loss: 0.0000 Acc: 0.9926\n",
      "running corrects:  2304\n",
      "test_np_med Loss: 0.0023 Acc: 0.6090\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "running corrects:  9445\n",
      "train_np_med Loss: 0.0000 Acc: 0.9919\n",
      "running corrects:  2302\n",
      "test_np_med Loss: 0.0023 Acc: 0.6085\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "running corrects:  9454\n",
      "train_np_med Loss: 0.0000 Acc: 0.9929\n",
      "running corrects:  2347\n",
      "test_np_med Loss: 0.0023 Acc: 0.6204\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "running corrects:  9454\n",
      "train_np_med Loss: 0.0000 Acc: 0.9929\n",
      "running corrects:  2351\n",
      "test_np_med Loss: 0.0023 Acc: 0.6215\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "running corrects:  9471\n",
      "train_np_med Loss: 0.0000 Acc: 0.9946\n",
      "running corrects:  2345\n",
      "test_np_med Loss: 0.0023 Acc: 0.6199\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "running corrects:  9469\n",
      "train_np_med Loss: 0.0000 Acc: 0.9944\n",
      "running corrects:  2357\n",
      "test_np_med Loss: 0.0023 Acc: 0.6231\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "running corrects:  9465\n",
      "train_np_med Loss: 0.0000 Acc: 0.9940\n",
      "running corrects:  2356\n",
      "test_np_med Loss: 0.0023 Acc: 0.6228\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "running corrects:  9479\n",
      "train_np_med Loss: 0.0000 Acc: 0.9955\n",
      "running corrects:  2324\n",
      "test_np_med Loss: 0.0023 Acc: 0.6143\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "running corrects:  9482\n",
      "train_np_med Loss: 0.0000 Acc: 0.9958\n",
      "running corrects:  2341\n",
      "test_np_med Loss: 0.0023 Acc: 0.6188\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "running corrects:  9477\n",
      "train_np_med Loss: 0.0000 Acc: 0.9953\n",
      "running corrects:  2321\n",
      "test_np_med Loss: 0.0023 Acc: 0.6135\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running corrects:  9477\n",
      "train_np_med Loss: 0.0000 Acc: 0.9953\n",
      "running corrects:  2346\n",
      "test_np_med Loss: 0.0023 Acc: 0.6201\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "running corrects:  9472\n",
      "train_np_med Loss: 0.0000 Acc: 0.9947\n",
      "running corrects:  2344\n",
      "test_np_med Loss: 0.0023 Acc: 0.6196\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "running corrects:  9477\n",
      "train_np_med Loss: 0.0000 Acc: 0.9953\n",
      "running corrects:  2347\n",
      "test_np_med Loss: 0.0023 Acc: 0.6204\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "running corrects:  9483\n",
      "train_np_med Loss: 0.0000 Acc: 0.9959\n",
      "running corrects:  2326\n",
      "test_np_med Loss: 0.0024 Acc: 0.6149\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "running corrects:  9473\n",
      "train_np_med Loss: 0.0000 Acc: 0.9949\n",
      "running corrects:  2334\n",
      "test_np_med Loss: 0.0023 Acc: 0.6170\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "running corrects:  9470\n",
      "train_np_med Loss: 0.0000 Acc: 0.9945\n",
      "running corrects:  2339\n",
      "test_np_med Loss: 0.0023 Acc: 0.6183\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "running corrects:  9482\n",
      "train_np_med Loss: 0.0000 Acc: 0.9958\n",
      "running corrects:  2318\n",
      "test_np_med Loss: 0.0023 Acc: 0.6127\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "running corrects:  9478\n",
      "train_np_med Loss: 0.0000 Acc: 0.9954\n",
      "running corrects:  2305\n",
      "test_np_med Loss: 0.0024 Acc: 0.6093\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "running corrects:  9470\n",
      "train_np_med Loss: 0.0000 Acc: 0.9945\n",
      "running corrects:  2328\n",
      "test_np_med Loss: 0.0024 Acc: 0.6154\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "running corrects:  9473\n",
      "train_np_med Loss: 0.0000 Acc: 0.9949\n",
      "running corrects:  2332\n",
      "test_np_med Loss: 0.0024 Acc: 0.6164\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "running corrects:  9483\n",
      "train_np_med Loss: 0.0000 Acc: 0.9959\n",
      "running corrects:  2337\n",
      "test_np_med Loss: 0.0024 Acc: 0.6178\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "running corrects:  9467\n",
      "train_np_med Loss: 0.0000 Acc: 0.9942\n",
      "running corrects:  2335\n",
      "test_np_med Loss: 0.0024 Acc: 0.6172\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "running corrects:  9469\n",
      "train_np_med Loss: 0.0000 Acc: 0.9944\n",
      "running corrects:  2311\n",
      "test_np_med Loss: 0.0024 Acc: 0.6109\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "running corrects:  9486\n",
      "train_np_med Loss: 0.0000 Acc: 0.9962\n",
      "running corrects:  2343\n",
      "test_np_med Loss: 0.0024 Acc: 0.6193\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "running corrects:  9487\n",
      "train_np_med Loss: 0.0000 Acc: 0.9963\n",
      "running corrects:  2336\n",
      "test_np_med Loss: 0.0024 Acc: 0.6175\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "running corrects:  9475\n",
      "train_np_med Loss: 0.0000 Acc: 0.9951\n",
      "running corrects:  2312\n",
      "test_np_med Loss: 0.0025 Acc: 0.6112\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "running corrects:  9476\n",
      "train_np_med Loss: 0.0000 Acc: 0.9952\n",
      "running corrects:  2320\n",
      "test_np_med Loss: 0.0023 Acc: 0.6133\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "running corrects:  9463\n",
      "train_np_med Loss: 0.0000 Acc: 0.9938\n",
      "running corrects:  2299\n",
      "test_np_med Loss: 0.0024 Acc: 0.6077\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "running corrects:  9467\n",
      "train_np_med Loss: 0.0000 Acc: 0.9942\n",
      "running corrects:  2306\n",
      "test_np_med Loss: 0.0024 Acc: 0.6096\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "running corrects:  9478\n",
      "train_np_med Loss: 0.0000 Acc: 0.9954\n",
      "running corrects:  2333\n",
      "test_np_med Loss: 0.0024 Acc: 0.6167\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "running corrects:  9491\n",
      "train_np_med Loss: 0.0000 Acc: 0.9967\n",
      "running corrects:  2323\n",
      "test_np_med Loss: 0.0024 Acc: 0.6141\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "running corrects:  9476\n",
      "train_np_med Loss: 0.0000 Acc: 0.9952\n",
      "running corrects:  2299\n",
      "test_np_med Loss: 0.0024 Acc: 0.6077\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "running corrects:  9475\n",
      "train_np_med Loss: 0.0000 Acc: 0.9951\n",
      "running corrects:  2318\n",
      "test_np_med Loss: 0.0024 Acc: 0.6127\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "running corrects:  9476\n",
      "train_np_med Loss: 0.0000 Acc: 0.9952\n",
      "running corrects:  2318\n",
      "test_np_med Loss: 0.0024 Acc: 0.6127\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "running corrects:  9480\n",
      "train_np_med Loss: 0.0000 Acc: 0.9956\n",
      "running corrects:  2344\n",
      "test_np_med Loss: 0.0025 Acc: 0.6196\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "running corrects:  9491\n",
      "train_np_med Loss: 0.0000 Acc: 0.9967\n",
      "running corrects:  2323\n",
      "test_np_med Loss: 0.0024 Acc: 0.6141\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "running corrects:  9481\n",
      "train_np_med Loss: 0.0000 Acc: 0.9957\n",
      "running corrects:  2315\n",
      "test_np_med Loss: 0.0024 Acc: 0.6119\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "running corrects:  9486\n",
      "train_np_med Loss: 0.0000 Acc: 0.9962\n",
      "running corrects:  2313\n",
      "test_np_med Loss: 0.0024 Acc: 0.6114\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "running corrects:  9486\n",
      "train_np_med Loss: 0.0000 Acc: 0.9962\n",
      "running corrects:  2310\n",
      "test_np_med Loss: 0.0024 Acc: 0.6106\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "running corrects:  9492\n",
      "train_np_med Loss: 0.0000 Acc: 0.9968\n",
      "running corrects:  2306\n",
      "test_np_med Loss: 0.0024 Acc: 0.6096\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "running corrects:  9490\n",
      "train_np_med Loss: 0.0000 Acc: 0.9966\n",
      "running corrects:  2345\n",
      "test_np_med Loss: 0.0024 Acc: 0.6199\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "running corrects:  9491\n",
      "train_np_med Loss: 0.0000 Acc: 0.9967\n",
      "running corrects:  2338\n",
      "test_np_med Loss: 0.0024 Acc: 0.6180\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "running corrects:  9484\n",
      "train_np_med Loss: 0.0000 Acc: 0.9960\n",
      "running corrects:  2320\n",
      "test_np_med Loss: 0.0024 Acc: 0.6133\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "running corrects:  9489\n",
      "train_np_med Loss: 0.0000 Acc: 0.9965\n",
      "running corrects:  2327\n",
      "test_np_med Loss: 0.0025 Acc: 0.6151\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "running corrects:  9486\n",
      "train_np_med Loss: 0.0000 Acc: 0.9962\n",
      "running corrects:  2354\n",
      "test_np_med Loss: 0.0024 Acc: 0.6223\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "running corrects:  9475\n",
      "train_np_med Loss: 0.0000 Acc: 0.9951\n",
      "running corrects:  2308\n",
      "test_np_med Loss: 0.0025 Acc: 0.6101\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "running corrects:  9475\n",
      "train_np_med Loss: 0.0000 Acc: 0.9951\n",
      "running corrects:  2319\n",
      "test_np_med Loss: 0.0024 Acc: 0.6130\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "running corrects:  9489\n",
      "train_np_med Loss: 0.0000 Acc: 0.9965\n",
      "running corrects:  2327\n",
      "test_np_med Loss: 0.0025 Acc: 0.6151\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "LR is set to 0.00125\n",
      "running corrects:  9478\n",
      "train_np_med Loss: 0.0000 Acc: 0.9954\n",
      "running corrects:  2362\n",
      "test_np_med Loss: 0.0024 Acc: 0.6244\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "running corrects:  9490\n",
      "train_np_med Loss: 0.0000 Acc: 0.9966\n",
      "running corrects:  2347\n",
      "test_np_med Loss: 0.0024 Acc: 0.6204\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "running corrects:  9487\n",
      "train_np_med Loss: 0.0000 Acc: 0.9963\n",
      "running corrects:  2348\n",
      "test_np_med Loss: 0.0024 Acc: 0.6207\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "running corrects:  9480\n",
      "train_np_med Loss: 0.0000 Acc: 0.9956\n",
      "running corrects:  2332\n",
      "test_np_med Loss: 0.0025 Acc: 0.6164\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "running corrects:  9504\n",
      "train_np_med Loss: 0.0000 Acc: 0.9981\n",
      "running corrects:  2324\n",
      "test_np_med Loss: 0.0025 Acc: 0.6143\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2332\n",
      "test_np_med Loss: 0.0025 Acc: 0.6164\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "running corrects:  9501\n",
      "train_np_med Loss: 0.0000 Acc: 0.9978\n",
      "running corrects:  2342\n",
      "test_np_med Loss: 0.0025 Acc: 0.6191\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "running corrects:  9503\n",
      "train_np_med Loss: 0.0000 Acc: 0.9980\n",
      "running corrects:  2351\n",
      "test_np_med Loss: 0.0024 Acc: 0.6215\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2351\n",
      "test_np_med Loss: 0.0024 Acc: 0.6215\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "running corrects:  9492\n",
      "train_np_med Loss: 0.0000 Acc: 0.9968\n",
      "running corrects:  2358\n",
      "test_np_med Loss: 0.0025 Acc: 0.6233\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "running corrects:  9500\n",
      "train_np_med Loss: 0.0000 Acc: 0.9977\n",
      "running corrects:  2359\n",
      "test_np_med Loss: 0.0024 Acc: 0.6236\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "running corrects:  9496\n",
      "train_np_med Loss: 0.0000 Acc: 0.9973\n",
      "running corrects:  2357\n",
      "test_np_med Loss: 0.0024 Acc: 0.6231\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "running corrects:  9497\n",
      "train_np_med Loss: 0.0000 Acc: 0.9974\n",
      "running corrects:  2347\n",
      "test_np_med Loss: 0.0025 Acc: 0.6204\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "running corrects:  9491\n",
      "train_np_med Loss: 0.0000 Acc: 0.9967\n",
      "running corrects:  2380\n",
      "test_np_med Loss: 0.0025 Acc: 0.6291\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "running corrects:  9491\n",
      "train_np_med Loss: 0.0000 Acc: 0.9967\n",
      "running corrects:  2358\n",
      "test_np_med Loss: 0.0025 Acc: 0.6233\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "running corrects:  9500\n",
      "train_np_med Loss: 0.0000 Acc: 0.9977\n",
      "running corrects:  2362\n",
      "test_np_med Loss: 0.0025 Acc: 0.6244\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "running corrects:  9501\n",
      "train_np_med Loss: 0.0000 Acc: 0.9978\n",
      "running corrects:  2384\n",
      "test_np_med Loss: 0.0024 Acc: 0.6302\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2375\n",
      "test_np_med Loss: 0.0025 Acc: 0.6278\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "running corrects:  9501\n",
      "train_np_med Loss: 0.0000 Acc: 0.9978\n",
      "running corrects:  2346\n",
      "test_np_med Loss: 0.0025 Acc: 0.6201\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "running corrects:  9503\n",
      "train_np_med Loss: 0.0000 Acc: 0.9980\n",
      "running corrects:  2334\n",
      "test_np_med Loss: 0.0025 Acc: 0.6170\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2354\n",
      "test_np_med Loss: 0.0025 Acc: 0.6223\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "running corrects:  9496\n",
      "train_np_med Loss: 0.0000 Acc: 0.9973\n",
      "running corrects:  2343\n",
      "test_np_med Loss: 0.0025 Acc: 0.6193\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "running corrects:  9504\n",
      "train_np_med Loss: 0.0000 Acc: 0.9981\n",
      "running corrects:  2340\n",
      "test_np_med Loss: 0.0025 Acc: 0.6186\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "running corrects:  9502\n",
      "train_np_med Loss: 0.0000 Acc: 0.9979\n",
      "running corrects:  2355\n",
      "test_np_med Loss: 0.0025 Acc: 0.6225\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "running corrects:  9508\n",
      "train_np_med Loss: 0.0000 Acc: 0.9985\n",
      "running corrects:  2340\n",
      "test_np_med Loss: 0.0025 Acc: 0.6186\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "running corrects:  9499\n",
      "train_np_med Loss: 0.0000 Acc: 0.9976\n",
      "running corrects:  2350\n",
      "test_np_med Loss: 0.0025 Acc: 0.6212\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2363\n",
      "test_np_med Loss: 0.0025 Acc: 0.6246\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "running corrects:  9501\n",
      "train_np_med Loss: 0.0000 Acc: 0.9978\n",
      "running corrects:  2365\n",
      "test_np_med Loss: 0.0025 Acc: 0.6252\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2376\n",
      "test_np_med Loss: 0.0024 Acc: 0.6281\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "running corrects:  9497\n",
      "train_np_med Loss: 0.0000 Acc: 0.9974\n",
      "running corrects:  2362\n",
      "test_np_med Loss: 0.0025 Acc: 0.6244\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "running corrects:  9505\n",
      "train_np_med Loss: 0.0000 Acc: 0.9982\n",
      "running corrects:  2345\n",
      "test_np_med Loss: 0.0025 Acc: 0.6199\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "running corrects:  9491\n",
      "train_np_med Loss: 0.0000 Acc: 0.9967\n",
      "running corrects:  2369\n",
      "test_np_med Loss: 0.0025 Acc: 0.6262\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2373\n",
      "test_np_med Loss: 0.0025 Acc: 0.6273\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2380\n",
      "test_np_med Loss: 0.0025 Acc: 0.6291\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2372\n",
      "test_np_med Loss: 0.0025 Acc: 0.6270\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "running corrects:  9497\n",
      "train_np_med Loss: 0.0000 Acc: 0.9974\n",
      "running corrects:  2374\n",
      "test_np_med Loss: 0.0025 Acc: 0.6275\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "running corrects:  9512\n",
      "train_np_med Loss: 0.0000 Acc: 0.9989\n",
      "running corrects:  2382\n",
      "test_np_med Loss: 0.0025 Acc: 0.6297\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "running corrects:  9505\n",
      "train_np_med Loss: 0.0000 Acc: 0.9982\n",
      "running corrects:  2338\n",
      "test_np_med Loss: 0.0026 Acc: 0.6180\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "running corrects:  9505\n",
      "train_np_med Loss: 0.0000 Acc: 0.9982\n",
      "running corrects:  2350\n",
      "test_np_med Loss: 0.0025 Acc: 0.6212\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2350\n",
      "test_np_med Loss: 0.0025 Acc: 0.6212\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "running corrects:  9503\n",
      "train_np_med Loss: 0.0000 Acc: 0.9980\n",
      "running corrects:  2354\n",
      "test_np_med Loss: 0.0025 Acc: 0.6223\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2366\n",
      "test_np_med Loss: 0.0025 Acc: 0.6254\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "running corrects:  9502\n",
      "train_np_med Loss: 0.0000 Acc: 0.9979\n",
      "running corrects:  2367\n",
      "test_np_med Loss: 0.0025 Acc: 0.6257\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2349\n",
      "test_np_med Loss: 0.0025 Acc: 0.6209\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "running corrects:  9506\n",
      "train_np_med Loss: 0.0000 Acc: 0.9983\n",
      "running corrects:  2377\n",
      "test_np_med Loss: 0.0025 Acc: 0.6283\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "running corrects:  9509\n",
      "train_np_med Loss: 0.0000 Acc: 0.9986\n",
      "running corrects:  2384\n",
      "test_np_med Loss: 0.0025 Acc: 0.6302\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "running corrects:  9502\n",
      "train_np_med Loss: 0.0000 Acc: 0.9979\n",
      "running corrects:  2347\n",
      "test_np_med Loss: 0.0026 Acc: 0.6204\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "running corrects:  9497\n",
      "train_np_med Loss: 0.0000 Acc: 0.9974\n",
      "running corrects:  2376\n",
      "test_np_med Loss: 0.0025 Acc: 0.6281\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "running corrects:  9498\n",
      "train_np_med Loss: 0.0000 Acc: 0.9975\n",
      "running corrects:  2378\n",
      "test_np_med Loss: 0.0025 Acc: 0.6286\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "running corrects:  9489\n",
      "train_np_med Loss: 0.0000 Acc: 0.9965\n",
      "running corrects:  2371\n",
      "test_np_med Loss: 0.0025 Acc: 0.6268\n",
      "\n",
      "Training complete in 4m 6s\n",
      "Best val Acc: 0.630188\n"
     ]
    }
   ],
   "source": [
    "model_lstm = train_model(rnn, criterion, optimizer, exp_lr_scheduler, '', num_epochs=num_epochs, model_name='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in get_loader(data_dir + '/' + test_np_dir, batch_size=3000)[0]:\n",
    "    # get the inputs\n",
    "\n",
    "    inputs, labels = data\n",
    "\n",
    "    # wrap them in Variable\n",
    "    if use_gpu:\n",
    "        x_test = Variable(inputs.view(-1, sequence_length, input_size).cuda())\n",
    "        y_test = labels.view(-1).cpu().numpy()\n",
    "        y_pred = model_lstm(x_test)\n",
    "        _, y_pred = torch.max(y_pred.data, 1)\n",
    "        y_pred = y_pred.cpu().view(-1).numpy()\n",
    "    break\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    print([round(cm[i][i], 2) for i in range(0, num_classes)])\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "class_int_to_name = {classes_dict[key]:key for key in classes_dict}\n",
    "names_of_classes = [class_int_to_name[i] for i in range(0, num_classes)]\n",
    "print(len(names_of_classes), len(y_test))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=names_of_classes,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=names_of_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_int_to_name = {classes_dict[key]:key for key in classes_dict}\n",
    "# class_int_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test set is not implemented yet\n",
    "\n",
    "# # Test the Model\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for images, labels in test_loader:\n",
    "#     images = Variable(images.view(-1, sequence_length, input_size))\n",
    "#     outputs = rnn(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum()\n",
    "\n",
    "# print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total)) \n",
    "\n",
    "# # Save the Model\n",
    "# # torch.save(rnn.state_dict(), 'rnn.pkl')\n",
    "# # torch.save(rnn, 'rnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_feat = 100\n",
    "# n_seq = 50 # fixed for now\n",
    "# n_video = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(4,5):\n",
    "#     tmp_data = np.random.random((n_seq+1, n_feat))\n",
    "#     np.save('data/features/Archery/v' + str(i) + '.npy', tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
