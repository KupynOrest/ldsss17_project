{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.ipynb_checkpoints',\n",
       " 'conv',\n",
       " 'conv features extract + lstm.ipynb',\n",
       " 'data',\n",
       " 'dataset_UCF-101.ipynb',\n",
       " 'features',\n",
       " 'Obj_detector',\n",
       " 'other_tutorials',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'RNN + loader + basic training.ipynb',\n",
       " 'RNN Tutorial 1.ipynb',\n",
       " 'rnn.pkl',\n",
       " 'transfer_learning_tutorial.ipynb']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from features.extractor import get_features\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "hidden_size = 128\n",
    "input_size = 512\n",
    "num_layers = 2\n",
    "batch_size = 2\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "num_classes = 3\n",
    "label_str_to_int = {'ApplyEyeMakeup': 0, 'Archery': 1, 'ApplyLipstick': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def check_size(address, sequence_size=50):\n",
    "#     x = np.load(address)\n",
    "#     print (x.shape)\n",
    "#     if x.shape[0] < sequence_size:\n",
    "#         return np.concatenate((x, np.zeros((sequence_size - x.shape[0], x.shape[1]))), axis=0)\n",
    "#     return x\n",
    "\n",
    "# # Data Loader (Input Pipeline)\n",
    "# def get_train_loader(path='data/features'):\n",
    "#     \"\"\"\n",
    "#     Function reads .npy files from path.\n",
    "#     Returns:\n",
    "#         dataloader, data classes (list), size of input object [n_sequence, n_features], lenght_of_dataset\n",
    "#     \"\"\"\n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "#     data_classes = os.listdir(path)\n",
    "#     label_int = 0\n",
    "#     for folder in data_classes:\n",
    "#         current_dir = path + '/' + folder + '/'\n",
    "        \n",
    "#         temp = [\n",
    "#             torch.Tensor(check_size(current_dir +  f, sequence_size=51)) for f in os.listdir(current_dir)\n",
    "#         ]  # Transform to torch tensors\n",
    "        \n",
    "#         targets += ([torch.LongTensor([label_int])] * len(temp))\n",
    "#         inputs += temp\n",
    "        \n",
    "#         label_int += 1\n",
    "        \n",
    "#     tensor_x = torch.stack(inputs)\n",
    "#     tensor_y = torch.stack(targets)\n",
    "#     print (tensor_x.size())\n",
    "#     my_dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)  # Create your datset\n",
    "#     my_dataloader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size)  # Create your dataloader\n",
    "    \n",
    "    \n",
    "#     return my_dataloader, data_classes, inputs[-1].size(), len(inputs)\n",
    "\n",
    "# train_loader, data_classes, [sequence_length, input_size], lenght_of_dataset = get_train_loader()\n",
    "\n",
    "# num_classes = len(data_classes)\n",
    "# print(train_loader, data_classes, sequence_length, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN (\n",
       "  (lstm): LSTM(512, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear (128 -> 3)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) .cuda()\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda()\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "#         print (x)\n",
    "#         print (h0, c0)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out.cuda()\n",
    "\n",
    "\n",
    "# rnn = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# class FinalModel_1(nn.Module):\n",
    "#     \"\"\" Conv net + LSTM \"\"\"\n",
    "#     def __init__(self, pretrained_model, input_size, hidden_size, num_layers, num_classes):\n",
    "#         self.pretrained_model = pretrained_model\n",
    "#         self.last_layer = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.last_layer(self.pretrained_model(x))\n",
    "rnn = RNN(input_size=512, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes).cuda()\n",
    "rnn\n",
    "# pretrained_model = torchvision.models.resnet18(pretrained=True)\n",
    "# model = FinalModel_1(pretrained_model=torch.resnet18(), input_size, hidden_size, num_layers, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a, b in  get_features(in_dir='data/data_subset/', batch_size=2):\n",
    "#     print(a, b.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_str_to_int['ApplyEyeMakeup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available:  True\n"
     ]
    }
   ],
   "source": [
    "print (\"GPU is available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 186 frames\n",
      "Loading movie with category Archery and 91 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [1/500], Loss: 2.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 135 frames\n",
      "Loading movie with category ApplyEyeMakeup and 187 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [2/500], Loss: 1.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 124 frames\n",
      "Loading movie with category ApplyEyeMakeup and 148 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [3/500], Loss: 0.4365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 124 frames\n",
      "Loading movie with category ApplyLipstick and 145 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [4/500], Loss: 2.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 166 frames\n",
      "Loading movie with category ApplyLipstick and 218 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [5/500], Loss: 2.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 142 frames\n",
      "Loading movie with category ApplyEyeMakeup and 181 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [6/500], Loss: 1.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 123 frames\n",
      "Loading movie with category Archery and 191 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [7/500], Loss: 1.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 68 frames\n",
      "Loading movie with category Archery and 67 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [8/500], Loss: 1.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 99 frames\n",
      "Loading movie with category Archery and 66 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [9/500], Loss: 1.3475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 130 frames\n",
      "Loading movie with category ApplyLipstick and 156 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [10/500], Loss: 1.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 265 frames\n",
      "Loading movie with category Archery and 131 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [11/500], Loss: 1.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 209 frames\n",
      "Loading movie with category Archery and 109 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [12/500], Loss: 1.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 259 frames\n",
      "Loading movie with category ApplyEyeMakeup and 96 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [13/500], Loss: 1.2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 114 frames\n",
      "Loading movie with category ApplyLipstick and 161 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [14/500], Loss: 1.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 214 frames\n",
      "Loading movie with category ApplyLipstick and 201 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [15/500], Loss: 1.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 140 frames\n",
      "Loading movie with category ApplyLipstick and 106 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [16/500], Loss: 1.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 188 frames\n",
      "Loading movie with category ApplyEyeMakeup and 134 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [17/500], Loss: 1.3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 201 frames\n",
      "Loading movie with category Archery and 111 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [18/500], Loss: 1.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 489 frames\n",
      "Loading movie with category ApplyEyeMakeup and 142 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [19/500], Loss: 1.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 112 frames\n",
      "Loading movie with category ApplyLipstick and 181 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [20/500], Loss: 1.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 158 frames\n",
      "Loading movie with category ApplyEyeMakeup and 171 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [21/500], Loss: 1.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 259 frames\n",
      "Loading movie with category Archery and 108 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [22/500], Loss: 1.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 99 frames\n",
      "Loading movie with category ApplyLipstick and 90 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [23/500], Loss: 1.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 125 frames\n",
      "Loading movie with category Archery and 135 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [24/500], Loss: 1.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 158 frames\n",
      "Loading movie with category Archery and 186 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [25/500], Loss: 1.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 207 frames\n",
      "Loading movie with category Archery and 132 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [26/500], Loss: 1.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 132 frames\n",
      "Loading movie with category ApplyEyeMakeup and 107 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [27/500], Loss: 1.2947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 116 frames\n",
      "Loading movie with category ApplyLipstick and 119 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [28/500], Loss: 1.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 227 frames\n",
      "Loading movie with category Archery and 176 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [29/500], Loss: 1.1579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 147 frames\n",
      "Loading movie with category ApplyEyeMakeup and 246 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [30/500], Loss: 1.2578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 143 frames\n",
      "Loading movie with category Archery and 148 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [31/500], Loss: 1.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 170 frames\n",
      "Loading movie with category ApplyEyeMakeup and 115 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [32/500], Loss: 1.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 169 frames\n",
      "Loading movie with category ApplyEyeMakeup and 138 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [33/500], Loss: 1.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 100 frames\n",
      "Loading movie with category ApplyLipstick and 370 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [34/500], Loss: 1.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 187 frames\n",
      "Loading movie with category ApplyEyeMakeup and 159 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [35/500], Loss: 1.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 118 frames\n",
      "Loading movie with category ApplyLipstick and 186 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [36/500], Loss: 1.1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 126 frames\n",
      "Loading movie with category ApplyEyeMakeup and 136 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [37/500], Loss: 1.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 107 frames\n",
      "Loading movie with category ApplyEyeMakeup and 121 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [38/500], Loss: 1.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 211 frames\n",
      "Loading movie with category Archery and 112 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [39/500], Loss: 1.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 97 frames\n",
      "Loading movie with category Archery and 81 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [40/500], Loss: 1.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 456 frames\n",
      "Loading movie with category ApplyEyeMakeup and 141 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [41/500], Loss: 1.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 176 frames\n",
      "Loading movie with category ApplyLipstick and 220 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [42/500], Loss: 1.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 160 frames\n",
      "Loading movie with category ApplyLipstick and 212 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [43/500], Loss: 1.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 219 frames\n",
      "Loading movie with category Archery and 106 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [44/500], Loss: 1.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 209 frames\n",
      "Loading movie with category ApplyEyeMakeup and 174 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [45/500], Loss: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 73 frames\n",
      "Loading movie with category ApplyEyeMakeup and 234 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [46/500], Loss: 1.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 208 frames\n",
      "Loading movie with category ApplyEyeMakeup and 177 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [47/500], Loss: 1.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 244 frames\n",
      "Loading movie with category ApplyEyeMakeup and 132 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [48/500], Loss: 0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 219 frames\n",
      "Loading movie with category Archery and 245 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [49/500], Loss: 1.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 226 frames\n",
      "Loading movie with category ApplyEyeMakeup and 217 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [50/500], Loss: 1.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 143 frames\n",
      "Loading movie with category ApplyEyeMakeup and 126 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [51/500], Loss: 1.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 167 frames\n",
      "Loading movie with category ApplyEyeMakeup and 120 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [52/500], Loss: 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 398 frames\n",
      "Loading movie with category Archery and 147 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [53/500], Loss: 1.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 183 frames\n",
      "Loading movie with category ApplyLipstick and 214 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [54/500], Loss: 1.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 263 frames\n",
      "Loading movie with category ApplyLipstick and 461 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [55/500], Loss: 1.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 170 frames\n",
      "Loading movie with category Archery and 165 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [56/500], Loss: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 195 frames\n",
      "Loading movie with category Archery and 166 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [57/500], Loss: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 197 frames\n",
      "Loading movie with category ApplyLipstick and 200 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [58/500], Loss: 1.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 143 frames\n",
      "Loading movie with category Archery and 96 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [59/500], Loss: 1.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 104 frames\n",
      "Loading movie with category Archery and 86 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [60/500], Loss: 1.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 150 frames\n",
      "Loading movie with category ApplyLipstick and 117 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [61/500], Loss: 1.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 158 frames\n",
      "Loading movie with category Archery and 95 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [62/500], Loss: 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 106 frames\n",
      "Loading movie with category Archery and 74 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [63/500], Loss: 0.9527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 104 frames\n",
      "Loading movie with category ApplyLipstick and 126 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [64/500], Loss: 1.4779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 194 frames\n",
      "Loading movie with category ApplyEyeMakeup and 169 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [65/500], Loss: 0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 209 frames\n",
      "Loading movie with category ApplyEyeMakeup and 297 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [66/500], Loss: 1.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category Archery and 116 frames\n",
      "Loading movie with category Archery and 151 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [67/500], Loss: 0.8694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyLipstick and 126 frames\n",
      "Loading movie with category ApplyLipstick and 109 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [68/500], Loss: 1.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movie with category ApplyEyeMakeup and 168 frames\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (labels, images) in enumerate(get_features(in_dir='data/data_subset/', batch_size=2, max_frames=sequence_length)):\n",
    "#         print (images.size(), type(images))\n",
    "        labels = torch.LongTensor([label_str_to_int[i] for i in labels]).cuda()\n",
    "        \n",
    "#         print (type(images), type(labels))\n",
    "#         print (images)\n",
    "#         print(labels)\n",
    "\n",
    "        images = Variable(images.view(-1, sequence_length, input_size))\n",
    "        labels = Variable(labels.view(-1))\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn(images.float())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, 1000//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test set is not implemented yet\n",
    "\n",
    "# # Test the Model\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for images, labels in test_loader:\n",
    "#     images = Variable(images.view(-1, sequence_length, input_size))\n",
    "#     outputs = rnn(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum()\n",
    "\n",
    "# print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total)) \n",
    "\n",
    "# # Save the Model\n",
    "# # torch.save(rnn.state_dict(), 'rnn.pkl')\n",
    "# # torch.save(rnn, 'rnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feat = 100\n",
    "n_seq = 50 # fixed for now\n",
    "n_video = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4,5):\n",
    "    tmp_data = np.random.random((n_seq+1, n_feat))\n",
    "    np.save('data/features/Archery/v' + str(i) + '.npy', tmp_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
